{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import libraries\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "from keras.layers import Dropout\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.models import Sequential\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from keras.constraints import maxnorm\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# To Load dataset\r\n",
    "filename = \"./Wine Quality/wine.csv\"\r\n",
    "df = pd.read_csv(filename, index_col='index')\r\n",
    "df = df.sample(frac=1).reset_index(drop=True) # Shuffle dataframe\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.056</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.99472</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.70</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.045</td>\n",
       "      <td>33.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.99760</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>67.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.99907</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.62</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>66.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.99760</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.030</td>\n",
       "      <td>18.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.99116</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.38</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            6.1              0.59         0.01             2.1      0.056   \n",
       "1            8.3              0.39         0.70            10.6      0.045   \n",
       "2            7.4              0.33         0.26            15.6      0.049   \n",
       "3            7.2              0.39         0.62            11.0      0.047   \n",
       "4            6.9              0.27         0.25             7.5      0.030   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                  5.0                  13.0  0.99472  3.52       0.56   \n",
       "1                 33.0                 169.0  0.99760  3.09       0.57   \n",
       "2                 67.0                 210.0  0.99907  3.06       0.68   \n",
       "3                 66.0                 178.0  0.99760  3.16       0.50   \n",
       "4                 18.0                 117.0  0.99116  3.09       0.38   \n",
       "\n",
       "   alcohol  quality  \n",
       "0     11.4        5  \n",
       "1      9.4        5  \n",
       "2      9.5        5  \n",
       "3      8.7        5  \n",
       "4     13.0        6  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# To convert binary classification of quality \r\n",
    "df['quality'] = df['quality'].apply(lambda x: 1 if x > 5 else 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.quality.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    4113\n",
       "0    2384\n",
       "Name: quality, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Creating a test/train split\r\n",
    "X = df.iloc[:, 0:11]\r\n",
    "y= df.iloc[:, 11]\r\n",
    "\r\n",
    "# Splitting the data set for training and validating \r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify=y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Define the scaler \r\n",
    "scaler = StandardScaler().fit(X_train)\r\n",
    "\r\n",
    "# Scale the train set\r\n",
    "X_train = scaler.transform(X_train)\r\n",
    "\r\n",
    "# Scale the test set\r\n",
    "X_test = scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Check the shape of the features and the target\r\n",
    "print(X_train.shape)\r\n",
    "print(X_test.shape)\r\n",
    "print(y_train.shape)\r\n",
    "print(y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5197, 11)\n",
      "(1300, 11)\n",
      "(5197,)\n",
      "(1300,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune Batch Size and Number of Epochs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Function to create model, required for KerasClassifier\r\n",
    "def create_model():\r\n",
    "    # create model\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(8, input_dim=11, activation='relu'))\r\n",
    "    model.add(Dense(12, activation='relu'))\r\n",
    "    model.add(Dense(1, activation='sigmoid'))\r\n",
    "    # Compile model\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "# fix random seed for reproducibility\r\n",
    "seed = 7\r\n",
    "np.random.seed(seed)\r\n",
    "\r\n",
    "# create model\r\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\r\n",
    "\r\n",
    "# define the grid search parameters\r\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\r\n",
    "epochs = [10, 50, 100, 150, 200]\r\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\r\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
    "grid_result = grid.fit(X_train, y_train)\r\n",
    "\r\n",
    "# summarize results\r\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
    "means = grid_result.cv_results_['mean_test_score']\r\n",
    "stds = grid_result.cv_results_['std_test_score']\r\n",
    "params = grid_result.cv_results_['params']\r\n",
    "for mean, stdev, param in zip(means, stds, params):\r\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.765632 using {'batch_size': 40, 'epochs': 150}\n",
      "0.756973 (0.007992) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.761975 (0.010937) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.763128 (0.015753) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.760242 (0.015759) with: {'batch_size': 10, 'epochs': 150}\n",
      "0.760436 (0.011322) with: {'batch_size': 10, 'epochs': 200}\n",
      "0.751009 (0.006193) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.764669 (0.009314) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.759091 (0.004125) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.765630 (0.014365) with: {'batch_size': 20, 'epochs': 150}\n",
      "0.762361 (0.006959) with: {'batch_size': 20, 'epochs': 200}\n",
      "0.736576 (0.009261) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.764283 (0.014060) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.760244 (0.009958) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.765632 (0.007410) with: {'batch_size': 40, 'epochs': 150}\n",
      "0.764285 (0.007153) with: {'batch_size': 40, 'epochs': 200}\n",
      "0.749274 (0.014519) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.758895 (0.015454) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.759476 (0.002894) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.761783 (0.012388) with: {'batch_size': 60, 'epochs': 150}\n",
      "0.762359 (0.014668) with: {'batch_size': 60, 'epochs': 200}\n",
      "0.737154 (0.014695) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.755818 (0.011532) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.759665 (0.013701) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.765053 (0.013425) with: {'batch_size': 80, 'epochs': 150}\n",
      "0.759282 (0.008786) with: {'batch_size': 80, 'epochs': 200}\n",
      "0.745814 (0.004067) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.761207 (0.007363) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.760820 (0.014922) with: {'batch_size': 100, 'epochs': 100}\n",
      "0.759476 (0.003072) with: {'batch_size': 100, 'epochs': 150}\n",
      "0.750046 (0.010198) with: {'batch_size': 100, 'epochs': 200}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune the Training Optimization Algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Function to create model, required for KerasClassifier\r\n",
    "def create_model_optimizer(optimizer='adam'):\r\n",
    "    # create model\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(8, input_dim=11, activation='relu'))\r\n",
    "    model.add(Dense(12, activation='relu'))\r\n",
    "    model.add(Dense(1, activation='sigmoid'))\r\n",
    "    # Compile model\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "# fix random seed for reproducibility\r\n",
    "seed = 7\r\n",
    "np.random.seed(seed)\r\n",
    "\r\n",
    "model = KerasClassifier(build_fn=create_model_optimizer, epochs=100, batch_size=60, verbose=0)\r\n",
    "\r\n",
    "# define the grid search parameters\r\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
    "param_grid = dict(optimizer=optimizer)\r\n",
    "grid1 = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
    "grid_result_optimizer = grid1.fit(X_train, y_train) # modify features here\r\n",
    "# summarize results\r\n",
    "print(\"Best: %f using %s\" % (grid_result_optimizer.best_score_, grid_result_optimizer.best_params_))\r\n",
    "means_optimizer = grid_result_optimizer.cv_results_['mean_test_score']\r\n",
    "stds_optimizer = grid_result_optimizer.cv_results_['std_test_score']\r\n",
    "params_optimizer = grid_result_optimizer.cv_results_['params']\r\n",
    "for mean, stdev, param in zip(means_optimizer, stds_optimizer, params_optimizer):\r\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.763711 using {'optimizer': 'Adam'}\n",
      "0.745046 (0.002613) with: {'optimizer': 'SGD'}\n",
      "0.751782 (0.009515) with: {'optimizer': 'RMSprop'}\n",
      "0.674235 (0.022871) with: {'optimizer': 'Adagrad'}\n",
      "0.541831 (0.073810) with: {'optimizer': 'Adadelta'}\n",
      "0.763711 (0.006241) with: {'optimizer': 'Adam'}\n",
      "0.745815 (0.003356) with: {'optimizer': 'Adamax'}\n",
      "0.758708 (0.012005) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune Network Weight Initialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Function to create model, required for KerasClassifier\r\n",
    "def create_model(init_mode='uniform'):\r\n",
    "    # create model\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(8, input_dim=11, kernel_initializer=init_mode, activation='relu'))\r\n",
    "    model.add(Dense(12, kernel_initializer=init_mode, activation='relu'))\r\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\r\n",
    "    # Compile model\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "# fix random seed for reproducibility\r\n",
    "seed = 7\r\n",
    "np.random.seed(seed)\r\n",
    "\r\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=60, verbose=0)\r\n",
    "\r\n",
    "# define the grid search parameters\r\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
    "param_grid = dict(init_mode=init_mode)\r\n",
    "\r\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
    "grid_result = grid.fit(X_train, y_train) # modify features here\r\n",
    "# summarize results\r\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
    "means = grid_result.cv_results_['mean_test_score']\r\n",
    "stds = grid_result.cv_results_['std_test_score']\r\n",
    "params = grid_result.cv_results_['params']\r\n",
    "for mean, stdev, param in zip(means, stds, params):\r\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.760246 using {'init_mode': 'glorot_normal'}\n",
      "0.758707 (0.006469) with: {'init_mode': 'uniform'}\n",
      "0.760054 (0.006038) with: {'init_mode': 'lecun_uniform'}\n",
      "0.752164 (0.005091) with: {'init_mode': 'normal'}\n",
      "0.633055 (0.008740) with: {'init_mode': 'zero'}\n",
      "0.760246 (0.008273) with: {'init_mode': 'glorot_normal'}\n",
      "0.754090 (0.004269) with: {'init_mode': 'glorot_uniform'}\n",
      "0.751781 (0.005597) with: {'init_mode': 'he_normal'}\n",
      "0.753705 (0.007012) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune the Neuron Activation Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Function to create model, required for KerasClassifier\r\n",
    "def create_model(activation='relu'):\r\n",
    "    # create model\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(8, input_dim=11, kernel_initializer='glorot_normal', activation=activation))\r\n",
    "    model.add(Dense(12, kernel_initializer='glorot_normal', activation=activation))\r\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal', activation='sigmoid'))\r\n",
    "    # Compile model\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "# fix random seed for reproducibility\r\n",
    "seed = 7\r\n",
    "np.random.seed(seed)\r\n",
    "\r\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=60, verbose=0)\r\n",
    "\r\n",
    "# define the grid search parameters\r\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
    "param_grid = dict(activation=activation)\r\n",
    "\r\n",
    "\r\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
    "grid_result = grid.fit(X_train, y_train) # modify features here\r\n",
    "# summarize results\r\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
    "means = grid_result.cv_results_['mean_test_score']\r\n",
    "stds = grid_result.cv_results_['std_test_score']\r\n",
    "params = grid_result.cv_results_['params']\r\n",
    "for mean, stdev, param in zip(means, stds, params):\r\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.761207 using {'activation': 'relu'}\n",
      "0.757745 (0.001181) with: {'activation': 'softmax'}\n",
      "0.748894 (0.001651) with: {'activation': 'softplus'}\n",
      "0.758901 (0.008172) with: {'activation': 'softsign'}\n",
      "0.761207 (0.004832) with: {'activation': 'relu'}\n",
      "0.757170 (0.008491) with: {'activation': 'tanh'}\n",
      "0.752742 (0.005054) with: {'activation': 'sigmoid'}\n",
      "0.751972 (0.005207) with: {'activation': 'hard_sigmoid'}\n",
      "0.734269 (0.004594) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune Dropout Regularization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Function to create model, required for KerasClassifier\r\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0):\r\n",
    "    # create model\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(8, input_dim=11, kernel_initializer='glorot_normal', activation='relu', kernel_constraint=maxnorm(weight_constraint)))\r\n",
    "    model.add(Dense(12, kernel_initializer='glorot_normal', activation='relu', kernel_constraint=maxnorm(weight_constraint)))\r\n",
    "    model.add(Dropout(dropout_rate))\r\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal', activation='sigmoid'))\r\n",
    "    # Compile model\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "# fix random seed for reproducibility\r\n",
    "seed = 7\r\n",
    "np.random.seed(seed)\r\n",
    "\r\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=60, verbose=0)\r\n",
    "\r\n",
    "# define the grid search parameters\r\n",
    "\r\n",
    "weight_constraint = [1, 2, 3, 4, 5]\r\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\r\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\r\n",
    "\r\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
    "grid_result = grid.fit(X_train, y_train) # modify features here\r\n",
    "# summarize results\r\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
    "means = grid_result.cv_results_['mean_test_score']\r\n",
    "stds = grid_result.cv_results_['std_test_score']\r\n",
    "params = grid_result.cv_results_['params']\r\n",
    "for mean, stdev, param in zip(means, stds, params):\r\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.764672 using {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
      "0.764672 (0.004076) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
      "0.754667 (0.007315) with: {'dropout_rate': 0.0, 'weight_constraint': 2}\n",
      "0.762363 (0.002831) with: {'dropout_rate': 0.0, 'weight_constraint': 3}\n",
      "0.755438 (0.009625) with: {'dropout_rate': 0.0, 'weight_constraint': 4}\n",
      "0.755823 (0.008150) with: {'dropout_rate': 0.0, 'weight_constraint': 5}\n",
      "0.756399 (0.007539) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
      "0.762750 (0.007811) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
      "0.757170 (0.015053) with: {'dropout_rate': 0.1, 'weight_constraint': 3}\n",
      "0.758900 (0.001719) with: {'dropout_rate': 0.1, 'weight_constraint': 4}\n",
      "0.759862 (0.010183) with: {'dropout_rate': 0.1, 'weight_constraint': 5}\n",
      "0.760633 (0.005697) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n",
      "0.763134 (0.008035) with: {'dropout_rate': 0.2, 'weight_constraint': 2}\n",
      "0.757939 (0.006306) with: {'dropout_rate': 0.2, 'weight_constraint': 3}\n",
      "0.755821 (0.006382) with: {'dropout_rate': 0.2, 'weight_constraint': 4}\n",
      "0.763132 (0.010267) with: {'dropout_rate': 0.2, 'weight_constraint': 5}\n",
      "0.760631 (0.001873) with: {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
      "0.755437 (0.002616) with: {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
      "0.760439 (0.002430) with: {'dropout_rate': 0.3, 'weight_constraint': 3}\n",
      "0.759861 (0.009556) with: {'dropout_rate': 0.3, 'weight_constraint': 4}\n",
      "0.759863 (0.007886) with: {'dropout_rate': 0.3, 'weight_constraint': 5}\n",
      "0.752743 (0.004234) with: {'dropout_rate': 0.4, 'weight_constraint': 1}\n",
      "0.754861 (0.008663) with: {'dropout_rate': 0.4, 'weight_constraint': 2}\n",
      "0.753320 (0.003949) with: {'dropout_rate': 0.4, 'weight_constraint': 3}\n",
      "0.759285 (0.005751) with: {'dropout_rate': 0.4, 'weight_constraint': 4}\n",
      "0.759668 (0.004626) with: {'dropout_rate': 0.4, 'weight_constraint': 5}\n",
      "0.757937 (0.002836) with: {'dropout_rate': 0.5, 'weight_constraint': 1}\n",
      "0.746201 (0.006368) with: {'dropout_rate': 0.5, 'weight_constraint': 2}\n",
      "0.754861 (0.009856) with: {'dropout_rate': 0.5, 'weight_constraint': 3}\n",
      "0.757168 (0.002071) with: {'dropout_rate': 0.5, 'weight_constraint': 4}\n",
      "0.753896 (0.008088) with: {'dropout_rate': 0.5, 'weight_constraint': 5}\n",
      "0.746201 (0.005582) with: {'dropout_rate': 0.6, 'weight_constraint': 1}\n",
      "0.753705 (0.005364) with: {'dropout_rate': 0.6, 'weight_constraint': 2}\n",
      "0.748316 (0.008014) with: {'dropout_rate': 0.6, 'weight_constraint': 3}\n",
      "0.751781 (0.003965) with: {'dropout_rate': 0.6, 'weight_constraint': 4}\n",
      "0.754090 (0.003794) with: {'dropout_rate': 0.6, 'weight_constraint': 5}\n",
      "0.756013 (0.001580) with: {'dropout_rate': 0.7, 'weight_constraint': 1}\n",
      "0.754089 (0.000476) with: {'dropout_rate': 0.7, 'weight_constraint': 2}\n",
      "0.751203 (0.008629) with: {'dropout_rate': 0.7, 'weight_constraint': 3}\n",
      "0.746199 (0.002212) with: {'dropout_rate': 0.7, 'weight_constraint': 4}\n",
      "0.748124 (0.006983) with: {'dropout_rate': 0.7, 'weight_constraint': 5}\n",
      "0.744083 (0.004926) with: {'dropout_rate': 0.8, 'weight_constraint': 1}\n",
      "0.746201 (0.013519) with: {'dropout_rate': 0.8, 'weight_constraint': 2}\n",
      "0.740427 (0.002122) with: {'dropout_rate': 0.8, 'weight_constraint': 3}\n",
      "0.735232 (0.004351) with: {'dropout_rate': 0.8, 'weight_constraint': 4}\n",
      "0.747353 (0.010464) with: {'dropout_rate': 0.8, 'weight_constraint': 5}\n",
      "0.717721 (0.007156) with: {'dropout_rate': 0.9, 'weight_constraint': 1}\n",
      "0.683660 (0.024945) with: {'dropout_rate': 0.9, 'weight_constraint': 2}\n",
      "0.697900 (0.010590) with: {'dropout_rate': 0.9, 'weight_constraint': 3}\n",
      "0.702713 (0.003551) with: {'dropout_rate': 0.9, 'weight_constraint': 4}\n",
      "0.712334 (0.001057) with: {'dropout_rate': 0.9, 'weight_constraint': 5}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune the Number of Neurons in the Hidden Layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Function to create model, required for KerasClassifier\r\n",
    "def create_model(neurons=1):\r\n",
    "    # create model\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(neurons, input_dim=11, kernel_initializer='glorot_normal', activation='relu', kernel_constraint=maxnorm(1)))\r\n",
    "    model.add(Dense(neurons, kernel_initializer='glorot_normal', activation='relu', kernel_constraint=maxnorm(1)))\r\n",
    "    model.add(Dropout(0.0))\r\n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal', activation='sigmoid'))\r\n",
    "    # Compile model\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "# fix random seed for reproducibility\r\n",
    "seed = 7\r\n",
    "np.random.seed(seed)\r\n",
    "\r\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=60, verbose=0)\r\n",
    "\r\n",
    "# define the grid search parameters\r\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\r\n",
    "param_grid = dict(neurons=neurons)\r\n",
    "\r\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
    "grid_result = grid.fit(X_train, y_train) # modify features here\r\n",
    "# summarize results\r\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
    "means = grid_result.cv_results_['mean_test_score']\r\n",
    "stds = grid_result.cv_results_['std_test_score']\r\n",
    "params = grid_result.cv_results_['params']\r\n",
    "for mean, stdev, param in zip(means, stds, params):\r\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.772563 using {'neurons': 30}\n",
      "0.670007 (0.046804) with: {'neurons': 1}\n",
      "0.757361 (0.007195) with: {'neurons': 5}\n",
      "0.757936 (0.007793) with: {'neurons': 10}\n",
      "0.762939 (0.006891) with: {'neurons': 15}\n",
      "0.765633 (0.006703) with: {'neurons': 20}\n",
      "0.772370 (0.007022) with: {'neurons': 25}\n",
      "0.772563 (0.006101) with: {'neurons': 30}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# COACHES' NOTES: good work, but this is not true grid search, in a true grid search, you would test every combination of your different ranges, here you fixed all parameters and varied just one.\r\n",
    "# This is a proper way of working/saving time if you know what you're doing.\r\n",
    "\r\n",
    "# COACHES' NOTES: Overall, you did well on this assignment."
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}